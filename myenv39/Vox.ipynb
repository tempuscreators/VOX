{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7bb1c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ejhaw\\VOX FineTuned\\myenv39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad024a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:52<00:00, 86.34s/it]\n",
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fc58ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial tokenizer config: LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-Instruct-v0.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Debugging: Print tokenizer's initial configuration\n",
    "print(\"Initial tokenizer config:\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd04546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting new padding token.\n"
     ]
    }
   ],
   "source": [
    "# Set padding token explicitly\n",
    "if tokenizer.pad_token is None:\n",
    "    print(\"Setting new padding token.\")\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "else:\n",
    "    print(\"Tokenizer already has padding token:\", tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765fb785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32001, 4096)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize model's token embeddings\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381720e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model's padding token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ea7b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated tokenizer config: LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-Instruct-v0.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32000: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Debugging: Print tokenizer's updated configuration\n",
    "print(\"Updated tokenizer config:\", tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78f122",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Rest of your script..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9fd6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic logging setup for file\n",
    "logging.basicConfig(filename='training_log.txt', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8b15fa4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize_data(text):\n",
    "    return tokenizer(text, padding='max_length', truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00875587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None):\n",
    "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        self.labels = torch.tensor(labels) if labels is not None else torch.zeros(len(texts), dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137e7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c1263b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data\n",
    "csv_file = 'C:\\\\Users\\\\ejhaw\\\\VoxPromtTuning.csv'  # Replace with your CSV file path\n",
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "562e746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'GeneratedPrompt' and optionally 'Labels' if available\n",
    "prompts = data['GeneratedPrompt'].tolist()\n",
    "labels = [0] * len(prompts)  # Assuming dummy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e2f890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and validation sets\n",
    "train_prompts, val_prompts, train_labels, val_labels = train_test_split(prompts, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5fa3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of MyDataset for training and validation\n",
    "train_dataset = MyDataset(train_prompts, train_labels)\n",
    "val_dataset = MyDataset(val_prompts, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a75f606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "809128d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 3\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52e7ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping parameters\n",
    "early_stopping_patience = 2\n",
    "best_val_loss = np.inf\n",
    "no_improvement_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5449530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training Loop with Early Stopping\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    logging.info(f'Epoch {epoch + 1} Average Training Loss: {avg_train_loss}')\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['labels']\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    logging.info(f'Epoch {epoch + 1} Average Validation Loss: {avg_val_loss}')\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "        if no_improvement_epochs >= early_stopping_patience:\n",
    "            logging.info(f'Early stopping triggered after epoch {epoch + 1}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b738ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_pretrained('./my_mistral_model')\n",
    "tokenizer.save_pretrained('./my_mistral_model')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "myenv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
