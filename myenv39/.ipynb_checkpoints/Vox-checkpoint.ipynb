{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb1c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad024a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging: Print tokenizer's initial configuration\n",
    "print(\"Initial tokenizer config:\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd04546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set padding token explicitly\n",
    "if tokenizer.pad_token is None:\n",
    "    print(\"Setting new padding token.\")\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "else:\n",
    "    print(\"Tokenizer already has padding token:\", tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765fb785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize model's token embeddings\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381720e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model's padding token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging: Print tokenizer's updated configuration\n",
    "print(\"Updated tokenizer config:\", tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78f122",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Rest of your script..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9fd6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic logging setup for file\n",
    "logging.basicConfig(filename='training_log.txt', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b15fa4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize_data(text):\n",
    "    return tokenizer(text, padding='max_length', truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00875587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None):\n",
    "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        self.labels = torch.tensor(labels) if labels is not None else torch.zeros(len(texts), dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137e7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1263b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data\n",
    "csv_file = 'C:\\\\Users\\\\ejhaw\\\\VoxPromtTuning.csv'  # Replace with your CSV file path\n",
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'GeneratedPrompt' and optionally 'Labels' if available\n",
    "prompts = data['GeneratedPrompt'].tolist()\n",
    "labels = [0] * len(prompts)  # Assuming dummy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and validation sets\n",
    "train_prompts, val_prompts, train_labels, val_labels = train_test_split(prompts, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of MyDataset for training and validation\n",
    "train_dataset = MyDataset(train_prompts, train_labels)\n",
    "val_dataset = MyDataset(val_prompts, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809128d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 3\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping parameters\n",
    "early_stopping_patience = 2\n",
    "best_val_loss = np.inf\n",
    "no_improvement_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d270045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with Early Stopping\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    logging.info(f'Epoch {epoch + 1} Average Training Loss: {avg_train_loss}')\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['labels']\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    logging.info(f'Epoch {epoch + 1} Average Validation Loss: {avg_val_loss}')\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "        if no_improvement_epochs >= early_stopping_patience:\n",
    "            logging.info(f'Early stopping triggered after epoch {epoch + 1}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b738ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_pretrained('./my_mistral_model')\n",
    "tokenizer.save_pretrained('./my_mistral_model')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
